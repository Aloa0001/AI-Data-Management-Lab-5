{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/23 14:34:13 WARN Instrumentation: [b70c9fb0] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 2.855992731933797e-14\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler as va\n",
    "from pyspark.ml.regression import LinearRegression as lr\n",
    "from pyspark.ml.evaluation import RegressionEvaluator as re\n",
    "\n",
    "# Create a SparkSession\n",
    "spark_session_1 = SparkSession.builder.appName(\"TemperaturePrediction\").getOrCreate()\n",
    "\n",
    "# Define the schema for the dataset\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"station_id\", StringType(), True),\n",
    "        StructField(\"date\", IntegerType(), True),\n",
    "        StructField(\"observation_type\", StringType(), True),\n",
    "        StructField(\"value\", IntegerType(), True),\n",
    "        StructField(\"extra_info\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "data = spark_session_1.read.csv(\"./1800.csv\", schema=schema)\n",
    "\n",
    "# Filter the dataset to keep only the TMAX col\n",
    "tmax_data = data.filter(data.observation_type == \"TMAX\")\n",
    "\n",
    "# Prepare features\n",
    "vector_assembler = va(inputCols=[\"date\", \"value\"], outputCol=\"features\")\n",
    "data_with_features = vector_assembler.transform(tmax_data)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = data_with_features.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "# Instantiate the linear regression instance\n",
    "lr = lr(featuresCol=\"features\", labelCol=\"value\")\n",
    "\n",
    "# Train the model\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = re(labelCol=\"value\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark_session_1.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
