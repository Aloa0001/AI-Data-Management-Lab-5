{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Machine Learning Project with Mllib Pipline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize SparkSession & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://macbook-pro:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Titanic Data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11499a190>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from pyspark.sql import SparkSession as sps, functions as F, types as T\n",
    "\n",
    "from pyspark.ml import Pipeline as P\n",
    "\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer as si,\n",
    "    OneHotEncoder as ohe,\n",
    "    VectorAssembler as va,\n",
    ")\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier as rfc\n",
    "\n",
    "# Instantiate a Spark Session\n",
    "spark_session_p2 = sps.builder.master(\"local\").appName(\"Titanic Data\").getOrCreate()\n",
    "\n",
    "spark_session_p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+--------+------+------+----+-------+--------+\n",
      "|     0.0|   3.0|  male|22.0|   7.25|       S|\n",
      "|     1.0|   1.0|female|38.0|71.2833|       C|\n",
      "|     1.0|   3.0|female|26.0|  7.925|       S|\n",
      "|     1.0|   1.0|female|35.0|   53.1|       S|\n",
      "|     0.0|   3.0|  male|35.0|   8.05|       S|\n",
      "+--------+------+------+----+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark_session_p2.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(\"./data/titanic/train.csv\")\n",
    ")\n",
    "\n",
    "# Translate the string values into numeric (float) values\n",
    "df = df.select(\n",
    "    F.col(\"Survived\").cast(\"float\"),\n",
    "    F.col(\"Pclass\").cast(\"float\"),\n",
    "    F.col(\"Sex\"),\n",
    "    F.col(\"Age\").cast(\"float\"),\n",
    "    F.col(\"Fare\").cast(\"float\"),\n",
    "    F.col(\"Embarked\"),\n",
    ")\n",
    "\n",
    "# Display the first five rows\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing and features preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 562\n",
      "Number of test samples: 150\n"
     ]
    }
   ],
   "source": [
    "# Split the complete data into training and testing subsets\n",
    "train_df, test_df = df.na.drop().randomSplit([0.8, 0.2], 11)\n",
    "print(f\"Number of train samples: {str(train_df.count())}\")\n",
    "print(f\"Number of test samples: {str(test_df.count())}\")\n",
    "\n",
    "# Label Encoding for the categorical variables \"Sex\" and \"Embarked\" without \".fit\" or \".transform\"\n",
    "sex_indexer = si(inputCol=\"Sex\", outputCol=\"Gender\")\n",
    "embarked_indexer = si(inputCol=\"Embarked\", outputCol=\"Boarded\")\n",
    "\n",
    "# Assemble all the features with VectorAssembler\n",
    "input_cols = [\"Pclass\", \"Age\", \"Fare\", \"Gender\", \"Boarded\"]\n",
    "output_col = \"feature\"\n",
    "vector_assembler = va(inputCols=input_cols, outputCol=output_col)\n",
    "\n",
    "# Instantiate the Random Forest Classifier model\n",
    "rf = rfc(labelCol=\"Survived\", featuresCol=output_col, maxDepth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline declaration, stages transformers-setup, pipeline execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+----+-------+--------+------+-------+-----------------------------------+--------------------------------------+----------------------------------------+----------+\n",
      "|Survived|Pclass|Sex |Age |Fare   |Embarked|Gender|Boarded|feature                            |rawPrediction                         |probability                             |prediction|\n",
      "+--------+------+----+----+-------+--------+------+-------+-----------------------------------+--------------------------------------+----------------------------------------+----------+\n",
      "|0.0     |1.0   |male|19.0|263.0  |S       |0.0   |0.0    |[1.0,19.0,263.0,0.0,0.0]           |[12.37969443779637,7.620305562203627] |[0.6189847218898187,0.38101527811018143]|0.0       |\n",
      "|0.0     |1.0   |male|21.0|77.2875|S       |0.0   |0.0    |[1.0,21.0,77.2874984741211,0.0,0.0]|[10.511151869253803,9.488848130746197]|[0.5255575934626902,0.47444240653730985]|0.0       |\n",
      "|0.0     |1.0   |male|28.0|82.1708|C       |0.0   |1.0    |[1.0,28.0,82.1707992553711,0.0,1.0]|[9.143603958227631,10.856396041772369]|[0.45718019791138154,0.5428198020886185]|1.0       |\n",
      "|0.0     |1.0   |male|29.0|30.0   |S       |0.0   |0.0    |[1.0,29.0,30.0,0.0,0.0]            |[11.177669537757952,8.822330462242048]|[0.5588834768878976,0.4411165231121024] |0.0       |\n",
      "|0.0     |1.0   |male|29.0|66.6   |S       |0.0   |0.0    |[1.0,29.0,66.5999984741211,0.0,0.0]|[9.310270624894299,10.689729375105701]|[0.46551353124471495,0.534486468755285] |1.0       |\n",
      "+--------+------+----+----+-------+--------+------+-------+-----------------------------------+--------------------------------------+----------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup the pipeline\n",
    "pipe = P(stages=[sex_indexer, embarked_indexer, vector_assembler, rf])\n",
    "\n",
    "# Fit the Pipeline model\n",
    "pipeline = pipe.fit(train_df)\n",
    "\n",
    "# Predict on test data\n",
    "test_predictions = pipeline.transform(test_df)\n",
    "\n",
    "# Display the predictions head\n",
    "test_predictions.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+----------------------------------------+--------+----------+\n",
      "|feature                            |probability                             |Survived|prediction|\n",
      "+-----------------------------------+----------------------------------------+--------+----------+\n",
      "|[1.0,19.0,263.0,0.0,0.0]           |[0.6189847218898187,0.38101527811018143]|0.0     |0.0       |\n",
      "|[1.0,21.0,77.2874984741211,0.0,0.0]|[0.5255575934626902,0.47444240653730985]|0.0     |0.0       |\n",
      "|[1.0,28.0,82.1707992553711,0.0,1.0]|[0.45718019791138154,0.5428198020886185]|0.0     |1.0       |\n",
      "|[1.0,29.0,30.0,0.0,0.0]            |[0.5588834768878976,0.4411165231121024] |0.0     |0.0       |\n",
      "|[1.0,29.0,66.5999984741211,0.0,0.0]|[0.46551353124471495,0.534486468755285] |0.0     |1.0       |\n",
      "+-----------------------------------+----------------------------------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_display_format = test_predictions[\n",
    "    [\"feature\", \"probability\", \"Survived\", \"prediction\"]\n",
    "]\n",
    "\n",
    "prediction_display_format.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator as mcv\n",
    "\n",
    "evaluator = mcv(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(pipeline.transform(test_df))\n",
    "\n",
    "print(f\"Training set accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session_p2.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
