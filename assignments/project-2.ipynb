{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Machine Learning Project with Mllib Pipline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.' Initialize SparkSession & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://macbook-pro:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Titanic Data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15c054710>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from pyspark.sql import SparkSession as sps, functions as F, types as T\n",
    "\n",
    "from pyspark.ml import Pipeline as P\n",
    "\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer as si,\n",
    "    OneHotEncoder as ohe,\n",
    "    VectorAssembler as va,\n",
    ")\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier as rfc\n",
    "\n",
    "# Instantiate a Spark Session\n",
    "spark_session_p2 = sps.builder.master(\"local\").appName(\"Titanic Data\").getOrCreate()\n",
    "\n",
    "spark_session_p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+--------+------+------+----+-------+--------+\n",
      "|     0.0|   3.0|  male|22.0|   7.25|       S|\n",
      "|     1.0|   1.0|female|38.0|71.2833|       C|\n",
      "|     1.0|   3.0|female|26.0|  7.925|       S|\n",
      "|     1.0|   1.0|female|35.0|   53.1|       S|\n",
      "|     0.0|   3.0|  male|35.0|   8.05|       S|\n",
      "+--------+------+------+----+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark_session_p2.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(\"./data/titanic/train.csv\")\n",
    ")\n",
    "\n",
    "# Translate the string values into numeric (float) values\n",
    "df = df.select(\n",
    "    F.col(\"Survived\").cast(\"float\"),\n",
    "    F.col(\"Pclass\").cast(\"float\"),\n",
    "    F.col(\"Sex\"),\n",
    "    F.col(\"Age\").cast(\"float\"),\n",
    "    F.col(\"Fare\").cast(\"float\"),\n",
    "    F.col(\"Embarked\"),\n",
    ")\n",
    "\n",
    "# Display the first five rows\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing and features preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 562\n",
      "Number of test samples: 150\n"
     ]
    }
   ],
   "source": [
    "# Split the complete data into training and testing subsets\n",
    "train_df, test_df = df.na.drop().randomSplit([0.8, 0.2], 11)\n",
    "print(f\"Number of train samples: {str(train_df.count())}\")\n",
    "print(f\"Number of test samples: {str(test_df.count())}\")\n",
    "\n",
    "# Label Encoding for the categorical variables \"Sex\" and \"Embarked\" without \".fit\" or \".transform\"\n",
    "sex_indexer = si(inputCol=\"Sex\", outputCol=\"Gender\")\n",
    "embarked_indexer = si(inputCol=\"Embarked\", outputCol=\"Boarded\")\n",
    "\n",
    "# Assemble all the features with VectorAssembler\n",
    "input_cols = [\"Pclass\", \"Age\", \"Fare\", \"Gender\", \"Boarded\"]\n",
    "output_col = \"feature\"\n",
    "vector_assembler = va(inputCols=input_cols, outputCol=output_col)\n",
    "\n",
    "# Instantiate the Random Forest Classifier model\n",
    "rf = rfc(labelCol=\"Survived\", featuresCol=output_col, maxDepth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline declaration, stages transformers-setup, pipeline execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+----+-------+--------+------+-------+-----------------------------------+--------------------------------------+----------------------------------------+----------+\n",
      "|Survived|Pclass|Sex |Age |Fare   |Embarked|Gender|Boarded|feature                            |rawPrediction                         |probability                             |prediction|\n",
      "+--------+------+----+----+-------+--------+------+-------+-----------------------------------+--------------------------------------+----------------------------------------+----------+\n",
      "|0.0     |1.0   |male|19.0|263.0  |S       |0.0   |0.0    |[1.0,19.0,263.0,0.0,0.0]           |[12.455043053162068,7.544956946837932]|[0.6227521526581035,0.3772478473418966] |0.0       |\n",
      "|0.0     |1.0   |male|21.0|77.2875|S       |0.0   |0.0    |[1.0,21.0,77.2874984741211,0.0,0.0]|[9.994224982343995,10.005775017656003]|[0.4997112491171998,0.5002887508828001] |1.0       |\n",
      "|0.0     |1.0   |male|28.0|82.1708|C       |0.0   |1.0    |[1.0,28.0,82.1707992553711,0.0,1.0]|[9.397347589344438,10.602652410655562]|[0.4698673794672219,0.5301326205327781] |1.0       |\n",
      "|0.0     |1.0   |male|29.0|30.0   |S       |0.0   |0.0    |[1.0,29.0,30.0,0.0,0.0]            |[11.48146790172573,8.518532098274267] |[0.5740733950862865,0.42592660491371337]|0.0       |\n",
      "|0.0     |1.0   |male|29.0|66.6   |S       |0.0   |0.0    |[1.0,29.0,66.5999984741211,0.0,0.0]|[9.528712861499184,10.471287138500818]|[0.47643564307495917,0.5235643569250409]|1.0       |\n",
      "+--------+------+----+----+-------+--------+------+-------+-----------------------------------+--------------------------------------+----------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup the pipeline\n",
    "pipe = P(stages=[sex_indexer, embarked_indexer, vector_assembler, rf])\n",
    "\n",
    "# Fit the Pipeline model\n",
    "pipeline = pipe.fit(train_df)\n",
    "\n",
    "# Predict on test data\n",
    "test_predictions = pipeline.transform(test_df)\n",
    "\n",
    "# Display the predictions head\n",
    "test_predictions.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.8067\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator as mcv\n",
    "\n",
    "evaluator = mcv(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(pipeline.transform(test_df))\n",
    "\n",
    "print(f\"Training set accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session_p2.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
